{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a18babce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SETUP ==========\n",
    "import re\n",
    "import uuid\n",
    "from unstructured.partition.auto import partition\n",
    "from qdrant_client import QdrantClient, models\n",
    "from sentence_transformers import SentenceTransformer  # Changed import\n",
    "import ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Configuration\n",
    "CHUNK_METHODS = [\"sliding\", \"sentence\"]\n",
    "SLIDING_SIZE = 200\n",
    "SLIDING_OVERLAP = 50\n",
    "SENTENCE_MAX = 300\n",
    "MIN_CHUNK = 25\n",
    "\n",
    "EMBEDDING_MODEL = \"BAAI/bge-base-en-v1.5\"  # Official model name\n",
    "LLM_MODEL = \"llama3\"\n",
    "\n",
    "# Initialize clients\n",
    "qdrant = QdrantClient(host=\"localhost\", port=6333)\n",
    "embed_model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "llm = ChatOllama(model=LLM_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac286d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cleanup old collections\n",
    "# for coll in qdrant.get_collections().collections:\n",
    "#     if coll.name.startswith((\"rag_data_\", \"raw_data_\")):\n",
    "#         qdrant.delete_collection(coll.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7eb10f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collections ready:\n",
      "['rag_data_sliding', 'rag_data_sentence']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCollections ready:\")\n",
    "print([coll.name for coll in qdrant.get_collections().collections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e37128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TEXT PROCESSING ==========\n",
    "def clean_text(text):\n",
    "    if not text: return \"\"\n",
    "    text = re.sub(r'[^\\w\\s.,;:!?\\'-]', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def chunk_sentences(text):\n",
    "    text = clean_text(text)\n",
    "    if len(text) < MIN_CHUNK or not any(c.isalpha() for c in text):\n",
    "        return []\n",
    "    \n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    chunks, current = [], \"\"\n",
    "    \n",
    "    for s in sentences:\n",
    "        if len(current) + len(s) <= SENTENCE_MAX:\n",
    "            current += s + \" \"\n",
    "        else:\n",
    "            if current.strip(): chunks.append(current.strip())\n",
    "            current = s + \" \"\n",
    "    \n",
    "    if current.strip(): chunks.append(current.strip())\n",
    "    return chunks\n",
    "\n",
    "def chunk_sliding(text):\n",
    "    text = clean_text(text)\n",
    "    if len(text) < MIN_CHUNK or not any(c.isalpha() for c in text):\n",
    "        return []\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + SLIDING_SIZE\n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk: chunks.append(chunk)\n",
    "        start += SLIDING_SIZE - SLIDING_OVERLAP\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e232bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== DOCUMENT PROCESSING ==========\n",
    "def create_rag_collection(method):\n",
    "    \"\"\"Create fresh Qdrant collection for a chunking method\"\"\"\n",
    "    coll_name = f\"rag_data_{method}\"\n",
    "    \n",
    "    # Delete if collection exists\n",
    "    if qdrant.collection_exists(coll_name):\n",
    "        qdrant.delete_collection(coll_name)\n",
    "    \n",
    "    # Create collection\n",
    "    qdrant.create_collection(\n",
    "        collection_name=coll_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=embed_model.get_sentence_embedding_dimension(),\n",
    "            distance=models.Distance.COSINE\n",
    "        )\n",
    "    )\n",
    "    return coll_name\n",
    "\n",
    "def process_pdf_to_chunks(filepath, method):\n",
    "    elements = partition(filename=filepath, languages=[\"eng\"])\n",
    "    for el in elements:\n",
    "        text = el.text.strip()\n",
    "        \n",
    "        # Metadata extraction â€” update with real attributes if available in elements\n",
    "        page_num = getattr(el, \"page_number\", \"unknown\")\n",
    "        title = getattr(el, \"heading\", \"unknown\")\n",
    "        section = getattr(el, \"section\", \"unknown\")\n",
    "        author = getattr(el, \"author\", \"unknown\")\n",
    "        processed_at = datetime.now(timezone.utc).isoformat()\n",
    "        \n",
    "        if text:\n",
    "            for chunk in (chunk_sliding(text) if method == \"sliding\" else chunk_sentences(text)):\n",
    "                yield {\n",
    "                    \"chunk\": chunk,\n",
    "                    \"page\": page_num,\n",
    "                    \"title\": title,\n",
    "                    \"section\": section,\n",
    "                    \"author\": author,\n",
    "                    \"processed_at\": processed_at\n",
    "                }\n",
    "\n",
    "def store_chunks(chunks, filepath, method):\n",
    "    \"\"\"Store processed chunks in Qdrant\"\"\"\n",
    "    coll_name = create_rag_collection(method)\n",
    "\n",
    "    # Extract chunk texts to embed\n",
    "    chunk_texts = [c[\"chunk\"] for c in chunks]\n",
    "    embeddings = embed_model.encode(chunk_texts, normalize_embeddings=True)\n",
    "    \n",
    "    points = []\n",
    "    for chunk_data, embedding in zip(chunks, embeddings):\n",
    "        payload = {\n",
    "            \"text\": chunk_data[\"chunk\"],\n",
    "            \"source\": filepath,\n",
    "            \"method\": method,\n",
    "            \"page\": chunk_data.get(\"page\", \"unknown\"),\n",
    "            \"title\": chunk_data.get(\"title\", \"unknown\"),\n",
    "            \"section\": chunk_data.get(\"section\", \"unknown\"),\n",
    "            \"author\": chunk_data.get(\"author\", \"unknown\"),\n",
    "            \"processed_at\": chunk_data.get(\"processed_at\", datetime.now(timezone.utc).isoformat())\n",
    "        }\n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector=embedding.tolist(),\n",
    "                payload=payload\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    qdrant.upsert(coll_name, points)\n",
    "    return len(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9e89026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========== PROCESS DOCUMENT ==========\n",
    "# file_path = \"../../../data/files/rag.pdf\"\n",
    "\n",
    "# for method in CHUNK_METHODS:\n",
    "#     chunks = list(process_pdf_to_chunks(file_path, method))  # Use process_pdf_to_chunks\n",
    "#     stored = store_chunks(chunks, file_path, method)  # Use store_chunks\n",
    "#     print(f\"Stored {stored} {method} chunks\")\n",
    "\n",
    "# print(\"\\nCollections ready:\")\n",
    "# print([coll.name for coll in qdrant.get_collections().collections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba1100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== QUERY FUNCTIONS ==========\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = sum([x * y for x, y in zip(a, b)])\n",
    "    norm_a = sum([x ** 2 for x in a]) ** 0.5\n",
    "    norm_b = sum([x ** 2 for x in b]) ** 0.5\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "def similarity_search(query_embedding, method=\"sentence\", top_k=3):\n",
    "    points = qdrant.scroll(\n",
    "        collection_name=f\"rag_data_{method}\",\n",
    "        with_vectors=True,\n",
    "        with_payload=True\n",
    "    )[0]\n",
    "\n",
    "    scored_points = []\n",
    "    for point in points:\n",
    "        similarity = cosine_similarity(query_embedding, point.vector)\n",
    "        scored_points.append({\n",
    "            \"text\": point.payload['text'],\n",
    "            \"similarity\": similarity,\n",
    "            \"source\": point.payload.get('source', ''),\n",
    "            \"method\": point.payload.get('method', ''),\n",
    "            \"page\": point.payload.get('page', 'unknown'),\n",
    "            \"title\": point.payload.get('title', 'unknown'),\n",
    "            \"section\": point.payload.get('section', 'unknown'),\n",
    "            \"author\": point.payload.get('author', 'unknown'),\n",
    "            \"processed_at\": point.payload.get('processed_at', 'unknown')\n",
    "        })\n",
    "\n",
    "    # Sort by similarity descending\n",
    "    return sorted(scored_points, key=lambda x: x['similarity'], reverse=True)[:top_k]\n",
    "\n",
    "\n",
    "def search(query, method=\"sentence\", top_k=3):\n",
    "    \"\"\"Modified to use custom similarity\"\"\"\n",
    "    query_embedding = embed_model.encode(query, normalize_embeddings=True).tolist()\n",
    "    return similarity_search(query_embedding, method, top_k)\n",
    "\n",
    "\n",
    "def ask(query, method=\"sentence\"):\n",
    "    results = search(query, method)\n",
    "    if not results:\n",
    "        return \"No relevant information found.\"\n",
    "\n",
    "    # Compose context without scores for LLM\n",
    "    context = \"\\n\".join(f\"- {res['text']}\" for res in results)\n",
    "\n",
    "    # prompt = (\n",
    "    #     f\"Based ONLY on the following context, answer the question:\\n{context}\\n\\n\"\n",
    "    #     f\"Question: {query}\\nAnswer:\"\n",
    "    # )\n",
    "\n",
    "    prompt = (\n",
    "        f\"Based ONLY on the following retrieved context, provide the exact information without any modification or added explanation:\\n{context}\\n\\n\"\n",
    "        f\"Question: {query}\\nAnswer:\\n\"\n",
    "        \"(Do not generate or infer answers, only present the retrieved text exactly as it appears.)\"\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Print metadata for traceability\n",
    "    print(\"\\n--- Retrieved Chunks Metadata ---\")\n",
    "    for res in results:\n",
    "        print(\n",
    "            f\"Page: {res['page']}, Title: {res['title']}, Section: {res.get('section', 'unknown')}, \"\n",
    "            f\"Author: {res.get('author', 'unknown')}, Source: {res['source']}, \"\n",
    "            f\"Similarity: {res['similarity']:.3f}, Processed At: {res.get('processed_at', 'unknown')}\"\n",
    "        )\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4bfb4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_only(query, method=\"sentence\"):\n",
    "    results = search(query, method)\n",
    "    if not results:\n",
    "        return \"No relevant information found.\"\n",
    "\n",
    "    # Compose context without scores or prompt\n",
    "    context = \"\\n\".join(f\"- {res['text']}\" for res in results)\n",
    "\n",
    "    # Print metadata for traceability\n",
    "    print(\"\\n--- Retrieved Chunks Metadata ---\")\n",
    "    for res in results:\n",
    "        print(\n",
    "            f\"Page: {res['page']}, Title: {res['title']}, Section: {res.get('section', 'unknown')}, \"\n",
    "            f\"Author: {res.get('author', 'unknown')}, Source: {res['source']}, \"\n",
    "            f\"Similarity: {res['similarity']:.3f}, Processed At: {res.get('processed_at', 'unknown')}\"\n",
    "        )\n",
    "\n",
    "    # Return just the retrieved text as one string (or could return list of texts)\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad8895c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is Retrieval-Augmented Generation (RAG)?\n",
      "\n",
      "--- Retrieved Chunks Metadata ---\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.717, Processed At: 2025-08-12T12:54:06.656266+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.689, Processed At: 2025-08-12T12:54:06.650899+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.658, Processed At: 2025-08-12T12:54:06.655967+00:00\n",
      "A: - 163 Q. Leng, K. Uhlenhuth, and A. Polyzotis, Best practices for llm evaluation of rag applications, https: www.databricks.com blog LLM-auto-eval-best-practices-RAG, 2023.\n",
      "- o data corruption during retrieval. Secondly, incorporating tables into the data can complicate semantic similarity searches. When dealing with semi-structured data, one approach involves lever- aging\n",
      "- sentence argument linking, arXiv preprint arXiv:1911.03766, 2019.\n"
     ]
    }
   ],
   "source": [
    "# ========== ASK QUESTIONS ==========\n",
    "question = \"What is Retrieval-Augmented Generation (RAG)?\"\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", retrieve_only(question, method=\"sliding\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89942fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is Retrieval-Augmented Generation (RAG)?\n",
      "\n",
      "--- Retrieved Chunks Metadata ---\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.717, Processed At: 2025-08-12T12:54:06.656266+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.689, Processed At: 2025-08-12T12:54:06.650899+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.658, Processed At: 2025-08-12T12:54:06.655967+00:00\n",
      "A: Based on the provided context, there is no direct mention of what Retrieval-Augmented Generation (RAG) is. The relevant texts only discuss best practices for evaluating LLMs and semi-structured data, but do not define or explain RAG. Therefore, I can provide no information about RAG.\n"
     ]
    }
   ],
   "source": [
    "# ========== ASK QUESTIONS ==========\n",
    "question = \"What is Retrieval-Augmented Generation (RAG)?\"\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", ask(question, method=\"sliding\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d13778b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are the key limitations of Large Language Models (LLMs) that RAG aims to address?\n",
      "\n",
      "--- Retrieved Chunks Metadata ---\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.737, Processed At: 2025-08-12T12:54:55.866841+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.710, Processed At: 2025-08-12T12:54:55.868575+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.667, Processed At: 2025-08-12T12:54:55.869381+00:00\n",
      "A: There is no answer provided in the given context regarding the key limitations of Large Language Models (LLMs) that RAG aims to address. The provided text only mentions a \"notable paucity of research\" and discusses the evolution of RAG technologies and their application on different tasks, but does not mention LLMs or their limitations.\n"
     ]
    }
   ],
   "source": [
    "# ========== ASK QUESTIONS ==========\n",
    "question = \"What are the key limitations of Large Language Models (LLMs) that RAG aims to address?\"\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", ask(question, method=\"sentence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28806c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is Retrieval-Augmented Generation (RAG)?\n",
      "\n",
      "--- Retrieved Chunks Metadata ---\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.717, Processed At: 2025-08-12T12:54:06.656266+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.689, Processed At: 2025-08-12T12:54:06.650899+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.658, Processed At: 2025-08-12T12:54:06.655967+00:00\n",
      "A: Based on the provided context, Retrieval-Augmented Generation (RAG) is not explicitly defined in the given text. However, it can be inferred that RAG applications are being evaluated using Large Language Models (LLMs), which suggests that RAG might refer to a type of language processing application or model that uses LLMs.\n"
     ]
    }
   ],
   "source": [
    "# ========== ASK QUESTIONS ==========\n",
    "question = \"What is Retrieval-Augmented Generation (RAG)?\"\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", ask(question, method=\"sliding\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d17dec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are the three core components of a RAG framework?\n",
      "\n",
      "--- Retrieved Chunks Metadata ---\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.815, Processed At: 2025-08-12T12:54:55.868575+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.709, Processed At: 2025-08-12T12:54:55.866841+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.592, Processed At: 2025-08-12T12:54:55.865799+00:00\n",
      "A: Based on the provided context, there is no direct information about the three core components of a RAG (RAG) framework. The text only mentions three developmental paradigms within the RAG framework: Naive, Advanced, and Modular RAG, which represent progressive enhancements over their predecessors. However, it does not specify what these components are or how they function.\n",
      "\n",
      "Therefore, I can't provide an answer based on this context alone. If you could provide more information about the RAG framework, I'd be happy to help!\n"
     ]
    }
   ],
   "source": [
    "# ========== ASK QUESTIONS ==========\n",
    "question = \"What are the three core components of a RAG framework?\"\n",
    "print(\"\\nQ:\", question)\n",
    "print(\"A:\", ask(question, method=\"sentence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "703a4a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are the three core components of a RAG framework?\n",
      "\n",
      "--- Retrieved Chunks Metadata ---\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.710, Processed At: 2025-08-12T12:54:06.656266+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.626, Processed At: 2025-08-12T12:54:06.653362+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.560, Processed At: 2025-08-12T12:54:06.655967+00:00\n",
      "A: According to TABLE IV SUMMARY OF EVALUATION FRAMEWORKS from the provided context, the three core components of a RAG (Rationale and Argument Generation) framework are:\n",
      "\n",
      "1. **Rationale Generation**: This involves generating explanations for the model's predictions or decisions.\n",
      "2. **Argument Linking**: This involves linking the rationale to the original input or question, demonstrating how the generated explanation supports the predicted answer.\n",
      "3. **Explanation Evaluation**: This involves assessing the quality and relevance of the generated rationales and arguments.\n",
      "\n",
      "These three components are the core components of a RAG framework, as mentioned in the provided context.\n"
     ]
    }
   ],
   "source": [
    "# ========== ASK QUESTIONS ==========\n",
    "question = \"What are the three core components of a RAG framework?\"\n",
    "print(\"\\nQ:\", question)\n",
    "print(\"A:\", ask(question, method=\"sliding\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be7775eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: Explain the indexing process in Naive RAG.\n",
      "\n",
      "--- Retrieved Chunks Metadata ---\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.694, Processed At: 2025-08-12T12:54:55.868575+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.663, Processed At: 2025-08-12T12:54:55.865799+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.646, Processed At: 2025-08-12T12:54:55.866841+00:00\n",
      "A: Based on the provided context, I can attempt to answer your question.\n",
      "\n",
      "According to the text, it does not explicitly describe the indexing process in Naive RAG. However, since it is a part of the RAG system, we can infer that the indexing process might be similar to other retrieval-based systems. In general, indexing refers to the process of creating an inverted index or a data structure that allows for efficient querying and retrieval.\n",
      "\n",
      "Given the context, I would assume that Naive RAG, as the most basic paradigm, likely relies on simple keyword extraction or bag-of-words representation, without any advanced techniques like latent semantic analysis (LSA) or contextualized embeddings. This would result in a straightforward indexing process based on term frequency, possibly with some simple stopword removal.\n",
      "\n",
      "Please note that this is an educated guess based on the provided context and not explicitly stated in the text.\n"
     ]
    }
   ],
   "source": [
    "# ========== ASK QUESTIONS ==========\n",
    "question = \"Explain the indexing process in Naive RAG.\"\n",
    "print(\"\\nQ:\", question)\n",
    "print(\"A:\", ask(question, method=\"sentence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a150ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: Explain the indexing process in Naive RAG.\n",
      "\n",
      "--- Retrieved Chunks Metadata ---\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.685, Processed At: 2025-08-12T12:54:06.650899+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.681, Processed At: 2025-08-12T12:54:06.656266+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.647, Processed At: 2025-08-12T12:54:06.650875+00:00\n",
      "A: Based on the provided context, there is no mention of an \"indexing process\" or \"Naive RAG\". The text appears to be discussing data corruption, semantic similarity searches, and structured vs. semi-structured data, but does not mention indexing or RAG (possibly a typo). Therefore, I cannot provide an answer to this question based on the given context.\n"
     ]
    }
   ],
   "source": [
    "# ========== ASK QUESTIONS ==========\n",
    "question = \"Explain the indexing process in Naive RAG.\"\n",
    "print(\"\\nQ:\", question)\n",
    "print(\"A:\", ask(question, method=\"sliding\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c6fe63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are the key challenges in the retrieval phase of Naive RAG?\n",
      "\n",
      "--- Retrieved Chunks Metadata ---\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.745, Processed At: 2025-08-12T12:54:55.868575+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.698, Processed At: 2025-08-12T12:54:55.866841+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.684, Processed At: 2025-08-12T12:54:55.865799+00:00\n",
      "A: Based on the provided context, there is no mention of specific challenges related to the retrieval phase of Naive RAG. The passage only provides an overview of the three developmental paradigms within the RAG framework (Naive, Advanced, and Modular) but does not discuss the key challenges in the retrieval phase.\n"
     ]
    }
   ],
   "source": [
    "# ========== ASK QUESTIONS ==========\n",
    "question = \"What are the key challenges in the retrieval phase of Naive RAG?\"\n",
    "print(\"\\nQ:\", question)\n",
    "print(\"A:\", ask(question, method=\"sentence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9c514b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are the key challenges in the retrieval phase of Naive RAG?\n",
      "\n",
      "--- Retrieved Chunks Metadata ---\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.704, Processed At: 2025-08-12T12:54:06.656266+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.693, Processed At: 2025-08-12T12:54:06.650899+00:00\n",
      "Page: unknown, Title: unknown, Section: unknown, Author: unknown, Source: ../../../data/files/rag.pdf, Similarity: 0.680, Processed At: 2025-08-12T12:54:06.650875+00:00\n",
      "A: Based on the context, the answer is:\n",
      "\n",
      "data corruption during retrieval\n"
     ]
    }
   ],
   "source": [
    "# ========== ASK QUESTIONS ==========\n",
    "question = \"What are the key challenges in the retrieval phase of Naive RAG?\"\n",
    "print(\"\\nQ:\", question)\n",
    "print(\"A:\", ask(question, method=\"sliding\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DocQuery_&_Interview_Booker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
